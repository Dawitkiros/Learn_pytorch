{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHBDuBSafFv6pMXEPu3Gr4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dawitkiros/Learn_pytorch/blob/main/learnTensor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing torch and torch.nn**"
      ],
      "metadata": {
        "id": "KAtd3LMWG9Tg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch"
      ],
      "metadata": {
        "id": "gnAQL-0d_H2O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor\n",
        "A tensor is a multi-dimensional array, which is a generalization of vectors and matrices to potentially higher dimensions. In deep learning frameworks like PyTorch, tensors are used to store the data of inputs, outputs, and model parameters."
      ],
      "metadata": {
        "id": "j-dNUjP_Csg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a 2x3 tensor with random values\n",
        "tensor_example = torch.rand(30, 3)\n",
        "print(tensor_example)"
      ],
      "metadata": {
        "id": "1dySxgLcBD5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ReLU**\n",
        "The ReLU (Rectified Linear Unit) function is a non-linear activation function used in neural networks, defined as the positive part of its argument. nn.ReLU() applies the ReLU function element-wise."
      ],
      "metadata": {
        "id": "udzWmVPPC1vR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "relu = nn.ReLU()\n",
        "input_tensor = torch.tensor([-1.0, 0.0, -2.0, 2.0])\n",
        "output_tensor = relu(input_tensor)\n",
        "print(output_tensor)\n",
        "\n",
        "leakyrelu = nn.LeakyReLU(0.01)\n",
        "output_tensor2 = leakyrelu(input_tensor)\n",
        "print(output_tensor2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Zijv5AiCiHS",
        "outputId": "ea4c2c6b-ce82-4192-fe5d-84df4ddaedc4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 0., 0., 2.])\n",
            "tensor([-0.0100,  0.0000, -0.0200,  2.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dropout**\n",
        "\n",
        "Dropout is a regularization technique to prevent overfitting in neural networks. It randomly zeros some of the elements of the input tensor with probability p during training, which helps to make the model more robust and prevents overfitting on the training data."
      ],
      "metadata": {
        "id": "OGRHvuHbDji9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dropout = nn.Dropout(p=0.5)  # 50% probability to zero elements\n",
        "input_tensor = torch.randn(1, 10)  # Random tensor\n",
        "output_tensor = dropout(input_tensor)\n",
        "print(output_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyy0_561Dpud",
        "outputId": "8abd24c2-c57c-40a3-fab5-a980e098ef43"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0000, -0.0000, -0.0000,  0.0000, -2.5144, -0.0000,  0.8519,  0.7719,\n",
            "          0.3354,  0.0215]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2AhL1HT6Drtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Linear**\n",
        "\n",
        "A linear layer (also known as a fully connected layer) applies a linear transformation to the incoming data: y = xA^T + b. It's defined by two parameters: the number of input features (dim_in) and the number of output features (dim_out)."
      ],
      "metadata": {
        "id": "DbULVYdKD7ER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear_layer = nn.Linear(10, 5)  # 10 input features, 5 output features\n",
        "input_tensor = torch.rand(1, 10)  # Example input\n",
        "print(input_tensor)\n",
        "output_tensor = linear_layer(input_tensor)\n",
        "print(output_tensor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJNSQ8_aD-qh",
        "outputId": "5f6a6793-16e5-4b36-e8ce-0b766758328b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9869, 0.3562, 0.0473, 0.7138, 0.4077, 0.0247, 0.4701, 0.1823, 0.0083,\n",
            "         0.1875]])\n",
            "tensor([[-0.0203, -0.2691, -0.0706,  0.2397,  0.1808]],\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Softmax\n",
        "\n",
        "The Softmax function is used as the activation function for the output layer of a classification network. It turns logits (raw prediction scores) into probabilities by taking the exponentials of each output and then normalizing these values by dividing by the sum of all the exponentials."
      ],
      "metadata": {
        "id": "yFl0PnycERAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "softmax = nn.Softmax(dim=1)\n",
        "input_tensor = torch.randn(1, 3)  # Logits for 3 classes\n",
        "print(input_tensor)\n",
        "output_tensor = softmax(input_tensor)\n",
        "print(output_tensor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Oiwe5jmEFem",
        "outputId": "4e67fede-c83e-4191-f449-38b02592ad0a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4120,  0.1650, -0.2709]])\n",
            "tensor([[0.2543, 0.4528, 0.2928]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Autograd**\n",
        "PyTorch's automatic differentiation engine, torch.autograd, automatically computes gradients for tensor operations, which are essential for backpropagation. It allows you to define computational graphs dynamically and compute gradients automatically."
      ],
      "metadata": {
        "id": "Qyxa-AhvFYgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "y = x * 2\n",
        "y.backward(torch.tensor([1.0, 0.1, 0.01]))\n",
        "print(x.grad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPhGSV5cFj7L",
        "outputId": "8b2f6a9e-15e7-4ebe-ee0d-aa2c0691574a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.0000, 0.2000, 0.0200])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Optimizers:**\n",
        "Located under torch.optim, optimizers update the parameters (weights and biases) of the neural network with the gradients computed during backpropagation. Common optimizers include SGD, Adam, and RMSprop."
      ],
      "metadata": {
        "id": "Xm55QzemF4RE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # model.parameters() contains the parameters to optimize\n"
      ],
      "metadata": {
        "id": "ZJQo2Cm2F-SA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Datasets and DataLoaders**\n",
        "PyTorch provides these abstractions in torch.utils.data to handle loading the data, making it easier to batch, shuffle, and distribute data across multiple workers."
      ],
      "metadata": {
        "id": "VayTIEEnGJkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        # Initialize dataset.\n",
        "        pass\n",
        "    def __len__(self):\n",
        "        # Return the size of the dataset.\n",
        "        return len(self.data)\n",
        "    def __getitem__(self, idx):\n",
        "        # Fetch the data item at index `idx`.\n",
        "        return self.data[idx]\n",
        "\n",
        "dataset = CustomDataset()\n",
        "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n"
      ],
      "metadata": {
        "id": "BAx7bkjnGOvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Module:**\n",
        "The nn.Module class is a base class for all neural network modules in PyTorch. It is used to encapsulate parameters, and helpers for moving them between devices, exporting, loading, etc. Defining custom layers or models involves subclassing nn.Module."
      ],
      "metadata": {
        "id": "lfcHx6VnGZI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5)\n",
        "        self.conv2 = nn.Conv2d(20, 20, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        return F.relu(self.conv2(x))\n"
      ],
      "metadata": {
        "id": "E9OAo7dOGfkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Device Management:**\n",
        "PyTorch provides simple APIs to manage computation devices, allowing easy toggles between CPU and GPU for model training and inference."
      ],
      "metadata": {
        "id": "mskEIujhGnLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "tensor = tensor.to(device)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "3KalvDVeGqgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Saving and Loading Models:**\n",
        "PyTorch provides functionality to save and load models, which is crucial for pausing and resuming training, as well as deploying trained models."
      ],
      "metadata": {
        "id": "g7_RrAMnGxxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving\n",
        "torch.save(model.state_dict(), 'model_path.pth')\n",
        "\n",
        "# Loading\n",
        "model = TheModelClass(*args, **kwargs)\n",
        "model.load_state_dict(torch.load('model_path.pth'))\n"
      ],
      "metadata": {
        "id": "XLveYZkzG06z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K8ZzNCX2Gsez"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}